---
title: I have a patient with a problem. How do I figure out the possible causes
date: "2023-01-22"
enableToc: false
---

> [!info]
>
> 🌱 來自: [[sxtodx]]

# I have a patient with a problem. How do I figure out the possible causes #🚧 施工中

## I have a patient with a problem. How do I figure out the possible causes?

**Diane Altkorn, MD**





### THE DIAGNOSTIC PROCESS

Constructing a differential diagnosis, choosing diagnostic tests, and interpreting the results are key skills for all physicians. The diagnostic process, often called clinical reasoning, is complex, and errors in reasoning are thought to account for 17% of all adverse events. Diagnostic errors can occur due to faulty knowledge, faulty data gathering, and faulty information processing. While this chapter focuses on the reasoning process, remember that the data you acquire during the history taking and the physical exam, sometimes accompanied by preliminary laboratory tests, form the basis for your initial clinical impression. Even with flawless reasoning, your final diagnosis will be wrong if you do not start with accurate data. You must have well developed interviewing and physical examination skills.

Clinicians generally use dual reasoning processes to work through a case. System 1 reasoning, relatively rapid and intuitive, is based on pattern recognition and involves matching the patient’s presentation to an illness script, a prior example stored in memory. System 2 reasoning is a slower process in which the clinician uses an explicit analytic approach. System 1 thinking predominates when an experienced clinician encounters a straightforward case, with system 2 predominating when the case is more complicated or the clinician is less experienced. Most of the time there is an unconscious blending of the two systems. Clinicians should be aware of common biases in clinical reasoning (Table 1-1) and reflect upon their reasoning processes, looking for potential errors. This chapter breaks down the reasoning process into a series of steps that can help you work through large differential diagnoses, avoid biases, and retrospectively identify sources of error when your diagnosis is wrong.

**Table 1-1.** Common biases in clinical reasoning.



### A MODEL FOR CLINICAL REASONING (**Figure 1-1**)

#### Step 1: Identify the Problem

Be certain you understand what the patient is telling you. Sometimes “I’m tired” means “I become short of breath when I walk” and at other times means “My muscles are weak.” Construct a complete problem list consisting of the chief complaint, other acute symptoms and physical exam abnormalities, laboratory test abnormalities, chronic active problems (such as diabetes or hypertension), and important past problems (such as history of bowel obstruction or cancer). Problems that are likely to be related, such as shortness of breath and chest pain, should be grouped together. It is necessary to accurately identify the problem every time you evaluate a patient.



**Figure 1-1.** A model for clinical reasoning.

#### Step 2: Frame the Differential Diagnosis

The differential diagnosis should be framed in a way that **facilitates recall.** It might be possible to memorize long lists of causes, or differential diagnoses, for various problems. However, doing so would not necessarily lead to a useful organization of differentials that helps you remember or use them. Instead, it is preferable to use some kind of *problem-specific framework* to organize differentials into subcategories that are easier to remember and often clinically useful. Problem-specific frameworks can be **anatomic,** a framework often used for chest pain; **organ/system,** used for symptoms with very broad differentials like fatigue; **physiologic;** or based on **pivotal points** (defined below). Each chapter in *Symptom to Diagnosis* begins with a problem-specific framework for the differential. Using such frameworks has been shown to improve the diagnostic accuracy of medical students.

#### Step 3: Organize the Differential Diagnosis

Structuring the differential diagnosis into **clinically useful subgroups** can enable you to systematically work through the differential diagnosis. Sometimes the framework that is easiest to remember, such as grouping causes of dyspnea as cardiac or pulmonary, does not facilitate reasoning. Then, reorganizing the differential in a way that helps you understand the order in which to consider various diagnoses is necessary. The most clinically useful differentials are organized using pivotal points, one of a pair of opposing descriptors that compare and contrast clinical characteristics. Examples include old versus new headache, unilateral versus bilateral edema, and right lower quadrant pain versus epigastric pain. When pivotal points are used to frame the differential in the first place, it is not necessary to reorganize the differential to create a diagnostic algorithm.

You can frame and reorganize the differential yourself or find a source that does so in a way that makes sense to you. Each chapter in *Symptom to Diagnosis* contains a diagnostic algorithm that uses pivotal points to highlight logical reasoning pathways for each symptom. Steps 2 and 3 need to be done only once for each clinical problem you encounter; with experience, you will develop a repertoire of logically framed differentials and structured diagnostic approaches to problems you encounter.

#### Step 4: Limit the Differential Diagnosis

Since every disease in a differential may not be relevant to an individual patient, using **pivotal points** to create a **patient-specific** differential diagnosis can help narrow the list. Extracting pivotal points from the history and physical exam enables the clinician to limit a large, complete differential diagnosis to a more focused set of diagnoses pertinent to that particular patient. This step, and steps 5 through 9, should be included in your clinical reasoning for all patients.

#### Step 5: Explore Possible Diagnoses Using History and Physical Exam Findings

The next step is to look for *clinical clues* that point toward the most likely diagnosis. Does the patient have risk factors for a particular diagnosis? Does the patient’s description of the symptom suggest a likely cause? What have you observed on physical exam? *Focus on the positive—positive findings on history or physical exam are important* (65% of positive findings have a specificity > 80% and 43% of positive findings have a specificity > 90%). One-third have an LR\+ > 5, and 16% have an LR\+ > 10. Some very specific findings strongly suggest a specific diagnosis because they are rarely seen in patients without the disease, just as fingerprints point to a specific person because they are not seen in more than 1 individual. Such “fingerprint” findings will be marked with the symbol “FP” throughout the book. On the other hand, *do not be fooled by the negative; “classic” findings, especially individual findings, are often absent.* Only 21% of negative findings have a sensitivity > 80%, and only 11% of > 90%; just 7% have an LR– of < 0.1.

#### Step 6: Rank the Differential Diagnosis

Rank the differential diagnosis using the results obtained in Step 5. Even in a limited differential, not all diagnoses are equally likely or equally important. There are 4 approaches to ranking, or prioritizing, the differential diagnosis for a given problem: possibilistic, probabilistic, prognostic, and pragmatic.

**A.**  **Possibilistic approach:** Consider all known causes equally likely and simultaneously test for all of them. This is not a useful approach.

**B.**  **Probabilistic approach:** Consider first those disorders that are more likely; that is, those with the highest **pretest probability,** the probability that a disease is present before further testing is done.

**C.**  **Prognostic approach:** Consider the most serious diagnoses first.

**D.**  **Pragmatic approach:** Consider the diagnoses most responsive to treatment first.

Clearly, there are limitations to each of these individual approaches. Experienced clinicians simultaneously integrate probabilistic, prognostic, and pragmatic approaches when reorganizing and prioritizing a differential diagnosis in order to decide when testing is necessary and which test to order (Table 1-2). Clinicians use their knowledge of pivotal points; “fingerprints”; risk factors; typical or “textbook” presentations of disease; the variability of disease presentation; and prevalence and prognosis to select a leading hypothesis, must not miss hypotheses, and other active alternative hypotheses.

**Table 1-2.** Ranking the differential diagnosis.



#### Step 7: Test Your Hypotheses

Sometimes you are certain about the diagnosis based on the initial data and proceed to treatment. Most of the time, however, you require additional data to confirm your diagnostic hypotheses; in other words, you need to order diagnostic tests. Whenever you do so, you should understand how much the test will change the probability the patient has the disease in question.

#### Step 8: Re-rank the Differential Based on New Data

Remember, ruling out a disease is usually not enough; you must also determine the cause of the patient’s symptom. For example, you may have eliminated myocardial infarction (MI) as a cause of chest pain, but you still need to determine whether the pain is due to gastroesophageal reflux, muscle strain, aortic dissection, etc. Whenever you have not made a diagnosis, or when you encounter data that conflict with your original hypotheses, go back to the complete differential diagnosis and reprioritize it, taking the new data into consideration. Failure to reconsider the possibilities is called premature closure (see Table 1-1), one of the most common diagnostic errors made by clinicians.

#### Step 9: Test the New Hypotheses

Repeat the process until a diagnosis is reached.

### CONSTRUCTING A DIFFERENTIAL DIAGNOSIS

#### Step 1: Identify the Problem


**PATIENT** 

Mrs. S is a 58-year-old woman who comes to an urgent care clinic complaining of painful swelling of her left calf that has lasted for 2 days. She feels slightly feverish but has no other symptoms such as chest pain, shortness of breath, or abdominal pain. She has been completely healthy except for hypertension, osteoarthritis of her knees, and a cholecystectomy, with no history of other medical problems, surgeries, or fractures. Her only medication is hydrochlorothiazide. She had a normal pelvic exam and Pap smear 1 month ago. Physical exam shows that the circumference of her left calf is 3.5 cm greater than her right calf, and there is 1\+ pitting edema. The left calf is uniformly red and very tender, and there is slight tenderness along the popliteal vein and medial left thigh. There is a healing cut on her left foot. Her temperature is 37.7°C. The rest of her exam is normal.



**What is Mrs. S’s problem list?**


Problem lists should begin with the acute problems, followed by chronic active problems, ending with inactive problems. Mrs. S’s problems are (1) painful left leg edema with erythema, (2) hypertension, (3) osteoarthritis of the knees, and (4) status post cholecystectomy.

#### Step 2: Frame the Differential Diagnosis




**How do you frame the differential diagnosis for edema?**


As discussed in Chapter 17, Edema, the problem-specific organization of the full differential diagnosis starts with the distribution of the edema: generalized versus unilateral and limb versus localized. The causes of edema are fairly distinct for each of these subcategories. For instance, heart failure and chronic kidney disease cause generalized not unilateral edema.

#### Step 3: Organize the Differential Diagnosis

Since the edema differential is framed using the pivotal point of edema distribution, it is not necessary to organize it—step 3 has already been done.

#### Step 4: Limit the Differential Diagnosis




**What are the pivotal points in Mrs. S’s presentation? How would you limit the differential?**


Mrs. S has **acute unilateral leg** edema, a pivotal point that leads to a limited portion of the edema differential.

Diagnostic possibilities are now narrowed to a distinct subset of diseases that can be organized using an anatomic framework:

**A.**  Skin: Stasis dermatitis

**B.**  Soft tissue: Cellulitis

**C.**  Calf veins: Distal deep venous thrombosis (DVT)

**D.**  Knee: Ruptured Baker cyst

**E.**  Thigh veins: Proximal DVT

**F.**  Pelvis: Mass causing lymphatic obstruction

#### Step 5: Use History and Physical Exam Findings to Explore Possible Diagnoses

Consider the risk factors for each of the diagnostic possibilities as well as their associated symptoms and signs. For example, venous insufficiency is a risk factor for stasis dermatitis, and there may be hemosiderin staining along the malleolar surface on physical exam. Cellulitis often follows skin injury, and physical exam shows erythema and tenderness. DVT is more frequent in patients with underlying malignancy or recent immobilization, and there may be shortness of breath if the clot has embolized.

#### Step 6: Rank the Differential Diagnosis




**What are the important clinical clues in Mrs. S’s presentation? How would you rank and prioritize the limited differential? What is your leading hypothesis? What are your active alternatives?**


Mrs. S has a constellation of symptoms and signs supporting the diagnosis of cellulitis as the leading hypothesis: fever; an entry site for infection on her foot; and a red, tender, swollen leg. Even without risk factors for DVT, the active alternatives are proximal and calf DVT, being both common and “must not miss” diagnoses. If cellulitis and DVT are not present, ruptured Baker cyst and a pelvic mass should be considered. Finally, stasis dermatitis is excluded in a patient without a history of chronic leg swelling.




**How certain are you that Mrs. S has cellulitis? Should you treat her with antibiotics? How certain are you that she does not have DVT? Should you test for DVT?**


### THE ROLE OF DIAGNOSTIC TESTING

#### Step 7: Test Your Hypotheses




**I have a leading hypothesis and an active alternative—how do I know if I need to do a test or if I should start treatment?**


Once you have generated a leading hypothesis, with or without active alternatives, you need to decide whether you need further information before proceeding to treatment or before excluding other diagnoses. One way to think about this is in terms of certainty: how certain are you that your hypothesis is correct, and how much more certain do you need to be before starting treatment? Another way to think about this is in terms of **probability:** is **your pretest probability** of disease high enough or low enough that you do not need any further information from a test?

##### Determine the Pretest Probability

There are several ways to determine the pretest probability of your leading hypothesis and most important (often most serious) active alternatives: use a validated clinical decision rule (CDR), use prevalence data regarding the causes/etiologies of a symptom, and use your overall clinical impression.

**A.**  Use a validated CDR

**1.**  Investigators construct a list of potential predictors of a disease, and then examine a group of patients to determine whether the predictors and the disease are present.

**a.**  Logistic regression is then used to determine which predictors are most powerful and which can be omitted.

**b.**  The model is then validated by applying it in other patient populations.

**c.**  To simplify use, the clinical predictors in the model are often assigned point values, and different point totals correspond to different pretest probabilities.

**2.**  CDRs are infrequently available but are the most precise way of estimating pretest probability.

**3.**  If you can find a validated CDR, you can come up with an exact number (or a small range of numbers) for your pretest probability.

**B.**  Use information about the prevalence of etiologies for a symptom.

**1.**  You can sometimes find this information in textbooks or review articles.

**2.**  It is important to assess the quality of any studies you find before using the data.

**C.**  Use your overall clinical impression.

**1.**  This is a combination of what you know about disease prevalence and the match between the expected history and physical with that of the patient, mixed with your clinical experience, and the ever elusive attribute “clinical judgment.”

**2.**  This is just as imprecise as it sounds, and it has been shown that physicians are disproportionately influenced by their most recent clinical experience.

**3.**  Nevertheless, it has also been shown that the overall clinical impression of *experienced* clinicians has significant predictive value.

**4.**  Clinicians generally categorize pretest probability as low, moderate, or high. This rather vague categorization is still helpful. Do not get distracted thinking a number is necessary.

##### Consider the Potential Harms

Consider the potential harms of both a missed diagnosis and the treatment.

**A.**  It is very harmful to miss certain diagnoses, such as MI or pulmonary embolism, while it is not so harmful to miss others, such as mild carpal tunnel syndrome. You need to be very certain that life-threatening diseases are not present (that is, have a very low pretest probability), before excluding them without testing.

**B.**  Some treatments, such as thrombolytics, are more harmful than others, such as oral antibiotics; you need to be very certain that potentially harmful treatments are needed (that is, the pretest probability is very high) before prescribing them without testing.

### THE THRESHOLD MODEL: CONCEPTUALIZING PROBABILITIES

The ends of the bar in the threshold model represent 0% and 100% pretest probability. The **treatment threshold** is the probability above which the diagnosis is so likely you would treat the patient without further testing. The **test threshold** is the probability below which the diagnosis is so unlikely it is excluded without further testing (Figure 1-2).



**Figure 1-2.** The threshold model.

For example, consider Ms. A, a 19-year-old woman, who complains of 30 seconds of sharp right-sided chest pain after lifting a heavy box. The pretest probability of cardiac ischemia is so low that no further testing is necessary (Figure 1-3).



**Figure 1-3.** Ms. A’s threshold model.

Now consider Mr. B, a 60-year-old man, who smokes and has diabetes, hypertension, and 15 minutes of crushing substernal chest pain accompanied by nausea and diaphoresis, with an ECG showing ST-segment elevations in the anterior leads. The pretest probability of an acute MI is so high you would treat without further testing, such as measuring cardiac enzymes (Figure 1-4).



**Figure 1-4.** Mr. B’s threshold model.

Diagnostic tests are necessary when the pretest probability of disease is in the middle, above the test threshold and below the treatment threshold. A really useful test shifts the probability of disease so much that the **posttest probability** (the probability of disease after the test is done) crosses one of the thresholds (Figure 1-5). Test and treatment thresholds vary depending on the seriousness of the disease, the toxicity of the treatment, and the invasiveness of the test. For example, the treatment threshold for bacterial meningitis is low: it is a potentially fatal disease and antibiotics are a relatively nontoxic treatment. Treatments for lung cancer (such as chemotherapy or radiation therapy) have considerable toxicity, making the treatment threshold for lung cancer 100%; treatment is never given without a positive biopsy.



**Figure 1-5.** The role of diagnostic testing.




You are unable to find much information about estimating the pretest probability of cellulitis. You consider the potential risk of starting antibiotics to be low, and your overall clinical impression is that the pretest probability of cellulitis is high enough to cross the treatment threshold, so you start antibiotics.

You consider the pretest probability of DVT to be low, but not so low you can exclude it without testing, especially given the potential seriousness of this diagnostic possibility. You are able to find a CDR that helps you quantify the pretest probability and calculate that her pretest probability is 17% (see Chapter 15).



**You have read that duplex ultrasonography is the best noninvasive test for DVT. How good is it? Will a negative test rule out DVT?**


### UNDERSTANDING TEST RESULTS




**How do I know whether a test is really useful—whether it will really shift the probability of disease across a threshold?**


A perfect diagnostic test would always be positive in patients with the disease and would always be negative in patients without the disease (Figure 1-6). Since there are no perfect diagnostic tests, some patients with the disease have negative tests (false-negative), and some without the disease have positive tests (false-positive) (Figure 1-7).



**Figure 1-6.** A perfect diagnostic test. FN, false negative; FP, false positive; TN, true negative; TP, true positive.



**Figure 1-7.** A pictorial representation of test characteristics. FN, false negative; FP, false positive; TN, true negative; TP, true positive.

The **test characteristics** help you to know how often false results occur. They are determined by performing the test in patients known to have or not have the disease and recording the distribution of results (Table 1-3).

**Table 1-3.** Test characteristics.



Table 1-4 shows the test characteristics of duplex ultrasonography for the diagnosis of proximal DVT, based on a hypothetical group of 200 patients, 90 of whom have DVT.

**Table 1-4.** Results for calculating the test characteristics of duplex ultrasonography.



The **sensitivity** is the percentage of patients with DVT who have a true-positive (TP) test result:

Sensitivity = TP/total number of patients with DVT = 86/90 = 0.96 = 96%

Since tests with very high sensitivity have a very low percentage of false-negative results (in Table 1-4, 4/90 = 0.04 = 4%), a negative result is likely a true negative.

The **specificity** is the percentage of patients without DVT who have a true-negative (TN) test result:

Specificity = TN/total number of patients without DVT = 108/110 = 0.98 = 98%

Since tests with very high specificity have a low percentage of false-positive results (in Table 1-4, 2/110 = 0.02 = 2%), a positive result is likely a true positive.

The sensitivity and specificity are important attributes of a test, but they do not tell you whether the test result will change your pretest probability enough to move beyond the test or treatment thresholds; the shift in probability depends on the interactions between sensitivity, specificity, and pretest probability. The **likelihood ratio (LR),** the likelihood that a given test result would occur in a patient with the disease compared with the likelihood that the same result would occur in a patient without the disease, enables you to calculate how much the probability will shift.

The positive likelihood ratio (LR\+) tells you how likely it is that a result is a true-positive (TP), rather than a false-positive (FP):



**Positive LRs that are significantly above 1** indicate that a true-positive is much more likely than a false-positive, pushing you across the treatment threshold. An LR\+ > 10 causes a large shift in disease probability; in general, tests with LR\+ > 10 are very useful for ruling in disease. An LR\+ between 5 and 10 causes a moderate shift in probability, and tests with these LRs are somewhat useful. “Fingerprints,” findings that often rule in a disease, have very high positive LRs.

The negative likelihood ratio (LR–) tells you how likely it is that a result is a false-negative (FN), rather than a true-negative (TN):



**Negative LRs that are significantly less than 1** indicate that a false-negative is much less likely than a true-negative, pushing you below the test threshold. An LR– less than 0.1 causes a large shift in disease probability; in general, tests with LR– less than 0.1 are very useful for ruling out disease. An LR– between 0.1 and 0.5 causes a moderate shift in probability, and tests with these LRs are somewhat useful.

The closer the LR is to 1, the less useful the test; tests with a LR = 1 do not change probability at all and are useless. The threshold model in Figure 1-8 incorporates LRs and illustrates how tests can change disease probability.



**Figure 1-8.** Incorporating likelihood ratios (LRs) into the threshold model.

When you have a specific pretest probability, you can use the LR to calculate an exact posttest probability (see Box, Calculating an Exact Posttest Probability and Figure 1-9, Likelihood Ratio Nomogram). Table 1-5 shows some examples of how much LRs of different magnitudes change the pretest probability.



**Figure 1-9.** Likelihood ratio nomogram. Find the patient’s pretest probability on the left, and then draw a line through the likelihood ratio for the test to find the patient’s posttest probability.

**Table 1-5.** Calculating posttest probabilities using likelihood ratios (LRs) and pretest probabilities.



If you are using descriptive pretest probability terms such as low, moderate, and high, you can use LRs as follows:

**A.**  A test with an LR– of 0.1 or less will rule out a disease of low or moderate pretest probability.

**B.**  A test with an LR\+ of 10 or greater will rule in a disease of moderate or high probability.

**C.**  **Beware if the test result is the opposite of what you expected\!**

**1.**  If your pretest probability is high, a negative test rarely rules out the disease, no matter what the LR– is.

**2.**  If you pretest probability is low, a positive test rarely rules in the disease, no matter what the LR\+ is.

**3.**  *In these situations, you need to perform another test.*




Mrs. S has a normal duplex ultrasound scan. Based on the CDR, her pretest probability was 17%; given the LR– of 0.4, her posttest probability is < 1%, ruling out DVT (Figure 1-9). Since duplex ultrasonography is less sensitive for distal than for proximal DVT, clinical follow-up is particularly important. Some clinicians repeat the duplex ultrasound after 1 week to confirm the absence of DVT, and some clinicians order a D-dimer assay. When she returns for reexamination after 2 days, her leg looks much better, with minimal erythema, no edema, and no tenderness. The clinical response confirms your diagnosis of cellulitis, and no further diagnostic testing is necessary. (See Chapter 15 for a full discussion of the diagnostic approach to lower extremity DVT.)


### REFERENCES

Bowen JL. Educational strategies to promote clinical diagnostic reasoning. N Engl J Med. 2006;355:2217–25.

Coderre S, Jenkins D, McLaughlin K. Qualitative differences in knowledge structure are associated with diagnostic performance in medical students. Adv Health Sci Educ. 2009;14:677–84.

Croskerry P. From mindless to mindful practice—cognitive bias and clinical decision making. N Engl J Med. 2013;368:2445–8.

Graber ML, Franklin N, Gordon R. Diagnostic error in internal medicine. Arch Intern Med. 2005;165:1493–9.

Guyatt G, Rennie D, Cook D. *Users Guides to the Medical Literature,* 2nd ed. McGraw-Hill/JAMA. 2008.

Norman G, Eva K. Diagnostic error and clinical reasoning. Med Educ. 2010;44:94–100.

Richardson WS, Wilson MC, Guyatt GH, Cook DJ, Nishikawa J; for the Evidence-Based Medicine Working Group. Users’ Guides to the Medical Literature: XV. How to use an article about disease probability for differential diagnosis. JAMA. 1999;281:1214–9.

Sanders L. *Every Patient Tells a Story*. New York: Broadway Books; 2009.


**CALCULATING AN EXACT POSTTEST PROBABILITY**



Below is the process for calculating posttest probability given the pretest probability and LR.

A.  **Step 1**

1. Convert pretest probability to pretest odds.

2. Pretest odds = pretest probability/(1 − pretest probability).

B.  **Step 2**

1. Multiply pretest odds by the LR to get the posttest odds.

2. Posttest odds = pretest odds × LR.

C.  **Step 3**

1. Convert posttest odds to posttest probability.

2. Posttest probability = posttest odds/(1 \+ posttest odds).


For Mrs. S, the pretest probability of DVT was 17%, and the LR− for duplex ultrasound was 0.04.

A.  Step 1: pretest odds = pretest probability/(1 − pretest probability) = 0.17/(1 − 0.17) = 0.17/0.83 = 0.2

B.  Step 2: posttest odds = pretest odds × LR = 0.2 × 0.04 = 0.008

C.  Step 3: posttest probability = posttest odds/(1 \+ posttest odds) = 0.008/(1 \+ 0.008) = 0.008/1.008 = 0.008

So, Mrs. S’s posttest probability of proximal DVT is 0.8%.

